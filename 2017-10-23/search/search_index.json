{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome_to_mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"bash/","text":"Setting up Quest \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Bash"},{"location":"bash/#setting_up_quest","text":"For full documentation visit mkdocs.org .","title":"Setting up Quest"},{"location":"bash/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"bash/#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"cendr/","text":"Setting up Quest \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"CeNDR"},{"location":"cendr/#setting_up_quest","text":"For full documentation visit mkdocs.org .","title":"Setting up Quest"},{"location":"cendr/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"cendr/#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"domains/","text":"Domains \u00b6 Andersen Lab Domains are managed by Google.","title":"Domains"},{"location":"domains/#domains","text":"Andersen Lab Domains are managed by Google.","title":"Domains"},{"location":"google-cloud/","text":"Setting up Quest \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Google Cloud"},{"location":"google-cloud/#setting_up_quest","text":"For full documentation visit mkdocs.org .","title":"Setting up Quest"},{"location":"google-cloud/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"google-cloud/#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"labsite/","text":"Andersenlab.org \u00b6 Andersenlab.org Getting Started Software-Dependencies Cloning the repo Updating the site andersenlab.github.io Announcements General Announcements Publication Post Lab members Adding new lab members: Set Status to Former Remove lab members Funding Protocols Research Publications Photo Albums Software Getting Started \u00b6 The Andersen Lab website was built using jekyll and runs using the Github Pages service. Software-Dependencies \u00b6 Several software packages are required for editing/maintaining the Andersen Lab site. They can be installed using Homebrew : brew install ruby imagemagick exiftool python gem install jekyll # you may need to sudo install this. # If you get an error when trying to run pip, try: # brew link --overwrite python pip install metapub pyyaml ruby - Is used to run jekyll, which is the software that builds the site. imagemagick - Handles thumbnail generation and scaling photos. Its used in the build.sh script. exiftool Is used to extract data about photos as part of the build.sh script. python Used to retrieve information about publications and modify yaml files that are part of Cloning the repo \u00b6 To get started editing, clone the repo: git clone https://github.com/andersenlab/andersenlab.github.io This repo contains documents that get compiled into the Andersen Lab website. When you make changes to this repo and push them to GitHub, Github will trigger a 'build' of the labsite and update it. This usually takes less than a minute. Instructions for changing various aspects of the site are listed below. You can also use Github Desktop to manage changes to the site. If you want to edit the site locally and preview changes, run the following in the git repo directory: jekyll serve The site should become available at localhost:4000 and any changes you make will be reflected at that local url. Updating the site \u00b6 In order for any change to become visible, you need to use git. Any subsequent directions that suggest modifying, adding, or removing files assumes you will be committing these changes to the repo and pushing the commit to GitHub.com. See Git-SCM for a basic introduction to git. andersenlab.github.io \u00b6 The structure of the Andersen Lab repo looks like this: CNAME LICENSE README.md build.sh index.html _config.yml _data/ _includes/ _layouts/ _posts/ _site/ assets/ feeds/ files/ pages/ people/ publications/ scripts/ protocols/ funding/ The folders prefixed with Announcements \u00b6 Announcements are stored in the _posts folder. Posts are organized into folders by year. There is also a _photo_albums folder that you can ignore (more on this below). Two types of announcements can be made. A 'general' announcement regarding anything, or a new publication. General Announcements \u00b6 To add a new post create a new text file with the following naming scheme: YYYY-MM-DD-title.md For example: 2017-09-24-A new post.md The contents of the file should correspond to the following structure: --- title: \"The title of the post\" layout: post tags: news published: true --- The post content goes here! The top part surrounded by --- is known as the header and has to define a number of variables: layout: post , tags: news , and published: true should always be set and should not change. The only thing you will change is the title . Set a title, and add content below. Because we used a *.md extension when naming the file, we can use markdown in the post to create headings, links, images, and more. Publication Post \u00b6 New publication posts can be created. These posts embed a publication summary identical to what you see on the publication page. They follow the same paradigm as above except they require two additional lines in the header: subtitle: - Usually the title of the paper; Appears on homepage. PMID: - The pubmed identifier Example : --- title: \"Katie's paper accepted at <em>G3</em>!\" subtitle: \"Correlations of geneotype with climate parameters suggest <em>Caenorhabditis elegans</em> niche adaptations\" layout: post tags: news published: true PMID: 27866149 --- Congratulations to Katie for her paper accepted at G3! Lab members \u00b6 Adding new lab members: \u00b6 (1) - Add a photo of the individual to the people/ folder. (2) - Edit the _data/people.yaml file, and add the information about that individual. Each individual should have - at a minimum, the following: - first_name: <first name> last_name: <last name> title: <One of: Graduate Student; Research Associate; Undergrad; Postdoctoral Researcher> photo: <filename of the photo located in the people/ directory> Additional fields can also be added: - first_name: <first name> last_name: <last name> title: <One of: Graduate Student; Research Associate; Undergrad; Postdoctoral Researcher> pub_names: [\"<an array>\", \"<of possible>\", \"<publication>\", \"<names>\"] photo: <base filename of the photo located in the people/ directory; e.g. 'dan.jpg'> website: <website> description: <a description of research> email: <email> github: <github username> Note pub_names is a list of possible ways an individual is referenced in the author list of a publication. This creates links from the publications page back to lab members on the people page. Set Status to Former \u00b6 Lab members can be moved to the bottom of the people page under the 'former member' area. To do this add a former: true line for that individual and a current_status: line indicating what they are up to. For example: - first_name: Mostafa pub_names: - Zamanian M last_name: Zamanian description: My research broadly spans \"neglected disease\" genomics and drug discovery. I am currently working to uncover new genetic determinants of anthelmintic resistance and to develop genome editing technology for human pathogenic helminths. title: Postdoctoral Researcher, 2015-2017 photo: Mostafa2014.jpg former: true github: mzamanian email: zamanian@northwestern.edu current_status: Assistant Professor at UW Madison -- <a href='http://www.zamanianlab.org/'>Zamanian Lab Website</a> Remove lab members \u00b6 Remove the persons information from _data/people.yaml ; Optionally delete their photo. Funding \u00b6 Funding is managed using the funding/ folder in the root directory and the data file _data/funding_links.yaml . The funding/ folder has two subfolders: past/ and current/ for past funding and current funding. Rename the logo file to be lowercase and simple. To update funding simply place the logo of the institution providing funding in one of these folders and it will appear on the funding page under the heading corresponding to the subfolder in which it was placed. If you would like to add a link for the funding of that organization you can edit the _data/funding_links.yaml file. This file is structured as a set of basename: url pairs: nigms: https://www.nigms.nih.gov/Pages/default.aspx acs: http://www.cancer.org/ pew: http://www.pewtrusts.org/en niaid: https://www.niaid.nih.gov/ aws: https://aws.amazon.com/ weinberg: http://www.weinberg.northwestern.edu/ mod: http://www.marchofdimes.org/ cbc: http://www.chicagobiomedicalconsortium.org/ Each acronym above corresponds with an image file in the current/ or past/ folder. Notice that the extension (e.g. jpeg/png, etc) does not matter. Just use the basename of the file and its associated link here. Protocols \u00b6 Protocols are stored in the protocols/ folder and their titles and pdfs are managed in _data/protocols.yaml . To add a new protocol, add the PDF to the protocols/ folder. Then add these lines to the _data/protocols.yaml file: - Name: Title of Protocol file: filename_of_protocol_in_protocols_folder.pdf group: <em>C. elegans</em> Phenotyping methods name - The name of the protocol file - The filename of the protocol within the protocols/ folder. group - The grouping of the protocol; It will be nested under this grouping on the protocols page. - name: Semi-Quantitative Brood Assay file: SemiQuantitativeBroodAssay.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Pseudomonas aeruginosa</em> Fast-killing assay</a> file: FKAprotocol.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Staphylococcus aureus</em> killing assay</a> file: Staphaureus_Protocol.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Bacillus thuringiensis</em> toxin assay on plates</a> file: Bacillus-thuringiensis-toxin-plate-assay.pdf group: <em>C. elegans</em> Phenotyping Methods To remove a protocol, delete the pdf and remove the corresponding lines. Research \u00b6 The research portion of the site is structured as a set of sections - each devoted to a project/area. Navigate to /pages/research and you will see a set of files: research.html - This page controls the content at the top of the research page. It's an overview of research in the Andersen lab. You can edit the top portion between the <p>[content]</p> tags freely to modify the top of the research page. research-*.md - These are the individual projects. These files look like this: --- title: High-throughput approaches to understand conserved drug responses image: worms_drugs2.jpg order: 1 --- Because of the efforts of a number of highly dedicated scientists and citizen volunteers... To this end, we deep sequenced all of these strains... The page includes a header (the items located between --- ) which includes a number of important items. title - the title to display for the research area. image - An image for that research area/project. This is the base name of the image placed in /assets/img/research/ order - A number indicating the order you would like the page ot appear in. Order is descending and any set of numbers can be used to determine sort order (e.g. 1, 2, 5, 8, 1000). Publications \u00b6 Elements used to construct the publications page of the website are stored in two places: _data/pubs_data.yaml - The publications data stores authors, pub date, journal, etc. publications/ - The publications folder for PDFs, thumbnails, and supplementary files. (1) Download a PDF of the publication You will want to remove any additional PDF pages (e.g. cover sheets) if there are any present in the PDF. See this guide for information on removing pages from a PDF. Save the PDF to /publications/[year][tag] Where tag is a unique identifier for the publication. In general, these have been the first author or the journal or a combination of both. (Optional) PMID Known If the PubMed Identifier (PMID) is known for the publication, you can add it to the file publications/publications_list.txt . (2) Run build.sh The build.sh script does a variety of tasks for the website. For publications - it will generate thumbnails. It will also fetch information for publications and add it to the _data/pubs_data.yaml file if a PMID has been provided. If you did not add a PMID, you will have to manually add authors, journal, etc. to the _data/pubs_data.yaml file. (3) Edit _data/pubs_data.yaml The publication should now be added either manually or automatically to _data/pubs_data.yaml and should look something like this: - Authors: [Laricchia KM, Zdraljevic S, Cook DE, Andersen EC] Citations: 0 DOI: 10.1093/molbev/msx155 Date_Published: 2017 May 09 Journal: Molecular Biology and Evolution PMID: 28486636 Title: Natural variation in the distribution and abundance of transposable elements across the Caenorhabditis elegans species The first thing you will want to do is associate the publication with the PDF you added. Add a PDF line for that: - Authors: [Laricchia KM, Zdraljevic S, Cook DE, Andersen EC] Citations: 0 DOI: 10.1093/molbev/msx155 Date_Published: 2017 May 09 Journal: Molecular Biology and Evolution PMID: 28486636 Title: Natural variation in the distribution and abundance of transposable elements across the <em>Caenorhabditis elegans</em> species PDF: 2017Laricchia You can also italicize text by adding <em> tags around words as shown above ( <em>Caenorhabditis elegans</em> ). Important Before pushing any changes to GitHub, you will want to preview the changes locally using jekyll serve . (4) Add supplementary data Supplemental data and figures are stored in publications/[pdf_name] . For example, 2017Laricchia has an associated folder in publications/ where supplemental data and figures are stored. Photo Albums \u00b6 Photo albums can be added to the Andersen Labsite. Adding albums requires two utilities to be installed on your computer: (a) Image Magick (b) exiftool These can easily be installed with homebrew . should have been installed during Setup (above), but if not you can install them using the following: brew install imagemagick brew install exiftool (1) Place images in a folder and name it according to the following schema: YYYY-MM-DD-title For example, 2017-08-05-Hawaii Trip . (2) Move that folder to /people/albums/ (3) Run the build.sh script in the root of the andersenlab.github.io repo. The build.sh script will do the following: (a) Construct pages for the album being published. (b) Decrease the size of the images in the album (max width=1200). Note The build.sh script also performs other maintenance-related tasks. It is fine to run this script at anytime. You can run the script using: bash build.sh (4) Add the images using git and push to GitHub You can easily add all images using: git add *.jpg (5) Push changes to github git push Software \u00b6 If you can write software you should be able to figure out how to update this section. It's markdown/html and not overly complicated.","title":"Andersen Labsite"},{"location":"labsite/#andersenlaborg","text":"Andersenlab.org Getting Started Software-Dependencies Cloning the repo Updating the site andersenlab.github.io Announcements General Announcements Publication Post Lab members Adding new lab members: Set Status to Former Remove lab members Funding Protocols Research Publications Photo Albums Software","title":"Andersenlab.org"},{"location":"labsite/#getting_started","text":"The Andersen Lab website was built using jekyll and runs using the Github Pages service.","title":"Getting Started"},{"location":"labsite/#software-dependencies","text":"Several software packages are required for editing/maintaining the Andersen Lab site. They can be installed using Homebrew : brew install ruby imagemagick exiftool python gem install jekyll # you may need to sudo install this. # If you get an error when trying to run pip, try: # brew link --overwrite python pip install metapub pyyaml ruby - Is used to run jekyll, which is the software that builds the site. imagemagick - Handles thumbnail generation and scaling photos. Its used in the build.sh script. exiftool Is used to extract data about photos as part of the build.sh script. python Used to retrieve information about publications and modify yaml files that are part of","title":"Software-Dependencies"},{"location":"labsite/#cloning_the_repo","text":"To get started editing, clone the repo: git clone https://github.com/andersenlab/andersenlab.github.io This repo contains documents that get compiled into the Andersen Lab website. When you make changes to this repo and push them to GitHub, Github will trigger a 'build' of the labsite and update it. This usually takes less than a minute. Instructions for changing various aspects of the site are listed below. You can also use Github Desktop to manage changes to the site. If you want to edit the site locally and preview changes, run the following in the git repo directory: jekyll serve The site should become available at localhost:4000 and any changes you make will be reflected at that local url.","title":"Cloning the repo"},{"location":"labsite/#updating_the_site","text":"In order for any change to become visible, you need to use git. Any subsequent directions that suggest modifying, adding, or removing files assumes you will be committing these changes to the repo and pushing the commit to GitHub.com. See Git-SCM for a basic introduction to git.","title":"Updating the site"},{"location":"labsite/#andersenlabgithubio","text":"The structure of the Andersen Lab repo looks like this: CNAME LICENSE README.md build.sh index.html _config.yml _data/ _includes/ _layouts/ _posts/ _site/ assets/ feeds/ files/ pages/ people/ publications/ scripts/ protocols/ funding/ The folders prefixed with","title":"andersenlab.github.io"},{"location":"labsite/#announcements","text":"Announcements are stored in the _posts folder. Posts are organized into folders by year. There is also a _photo_albums folder that you can ignore (more on this below). Two types of announcements can be made. A 'general' announcement regarding anything, or a new publication.","title":"Announcements"},{"location":"labsite/#general_announcements","text":"To add a new post create a new text file with the following naming scheme: YYYY-MM-DD-title.md For example: 2017-09-24-A new post.md The contents of the file should correspond to the following structure: --- title: \"The title of the post\" layout: post tags: news published: true --- The post content goes here! The top part surrounded by --- is known as the header and has to define a number of variables: layout: post , tags: news , and published: true should always be set and should not change. The only thing you will change is the title . Set a title, and add content below. Because we used a *.md extension when naming the file, we can use markdown in the post to create headings, links, images, and more.","title":"General Announcements"},{"location":"labsite/#publication_post","text":"New publication posts can be created. These posts embed a publication summary identical to what you see on the publication page. They follow the same paradigm as above except they require two additional lines in the header: subtitle: - Usually the title of the paper; Appears on homepage. PMID: - The pubmed identifier Example : --- title: \"Katie's paper accepted at <em>G3</em>!\" subtitle: \"Correlations of geneotype with climate parameters suggest <em>Caenorhabditis elegans</em> niche adaptations\" layout: post tags: news published: true PMID: 27866149 --- Congratulations to Katie for her paper accepted at G3!","title":"Publication Post"},{"location":"labsite/#lab_members","text":"","title":"Lab members"},{"location":"labsite/#adding_new_lab_members","text":"(1) - Add a photo of the individual to the people/ folder. (2) - Edit the _data/people.yaml file, and add the information about that individual. Each individual should have - at a minimum, the following: - first_name: <first name> last_name: <last name> title: <One of: Graduate Student; Research Associate; Undergrad; Postdoctoral Researcher> photo: <filename of the photo located in the people/ directory> Additional fields can also be added: - first_name: <first name> last_name: <last name> title: <One of: Graduate Student; Research Associate; Undergrad; Postdoctoral Researcher> pub_names: [\"<an array>\", \"<of possible>\", \"<publication>\", \"<names>\"] photo: <base filename of the photo located in the people/ directory; e.g. 'dan.jpg'> website: <website> description: <a description of research> email: <email> github: <github username> Note pub_names is a list of possible ways an individual is referenced in the author list of a publication. This creates links from the publications page back to lab members on the people page.","title":"Adding new lab members:"},{"location":"labsite/#set_status_to_former","text":"Lab members can be moved to the bottom of the people page under the 'former member' area. To do this add a former: true line for that individual and a current_status: line indicating what they are up to. For example: - first_name: Mostafa pub_names: - Zamanian M last_name: Zamanian description: My research broadly spans \"neglected disease\" genomics and drug discovery. I am currently working to uncover new genetic determinants of anthelmintic resistance and to develop genome editing technology for human pathogenic helminths. title: Postdoctoral Researcher, 2015-2017 photo: Mostafa2014.jpg former: true github: mzamanian email: zamanian@northwestern.edu current_status: Assistant Professor at UW Madison -- <a href='http://www.zamanianlab.org/'>Zamanian Lab Website</a>","title":"Set Status to Former"},{"location":"labsite/#remove_lab_members","text":"Remove the persons information from _data/people.yaml ; Optionally delete their photo.","title":"Remove lab members"},{"location":"labsite/#funding","text":"Funding is managed using the funding/ folder in the root directory and the data file _data/funding_links.yaml . The funding/ folder has two subfolders: past/ and current/ for past funding and current funding. Rename the logo file to be lowercase and simple. To update funding simply place the logo of the institution providing funding in one of these folders and it will appear on the funding page under the heading corresponding to the subfolder in which it was placed. If you would like to add a link for the funding of that organization you can edit the _data/funding_links.yaml file. This file is structured as a set of basename: url pairs: nigms: https://www.nigms.nih.gov/Pages/default.aspx acs: http://www.cancer.org/ pew: http://www.pewtrusts.org/en niaid: https://www.niaid.nih.gov/ aws: https://aws.amazon.com/ weinberg: http://www.weinberg.northwestern.edu/ mod: http://www.marchofdimes.org/ cbc: http://www.chicagobiomedicalconsortium.org/ Each acronym above corresponds with an image file in the current/ or past/ folder. Notice that the extension (e.g. jpeg/png, etc) does not matter. Just use the basename of the file and its associated link here.","title":"Funding"},{"location":"labsite/#protocols","text":"Protocols are stored in the protocols/ folder and their titles and pdfs are managed in _data/protocols.yaml . To add a new protocol, add the PDF to the protocols/ folder. Then add these lines to the _data/protocols.yaml file: - Name: Title of Protocol file: filename_of_protocol_in_protocols_folder.pdf group: <em>C. elegans</em> Phenotyping methods name - The name of the protocol file - The filename of the protocol within the protocols/ folder. group - The grouping of the protocol; It will be nested under this grouping on the protocols page. - name: Semi-Quantitative Brood Assay file: SemiQuantitativeBroodAssay.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Pseudomonas aeruginosa</em> Fast-killing assay</a> file: FKAprotocol.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Staphylococcus aureus</em> killing assay</a> file: Staphaureus_Protocol.pdf group: <em>C. elegans</em> Phenotyping Methods - name: <em>Bacillus thuringiensis</em> toxin assay on plates</a> file: Bacillus-thuringiensis-toxin-plate-assay.pdf group: <em>C. elegans</em> Phenotyping Methods To remove a protocol, delete the pdf and remove the corresponding lines.","title":"Protocols"},{"location":"labsite/#research","text":"The research portion of the site is structured as a set of sections - each devoted to a project/area. Navigate to /pages/research and you will see a set of files: research.html - This page controls the content at the top of the research page. It's an overview of research in the Andersen lab. You can edit the top portion between the <p>[content]</p> tags freely to modify the top of the research page. research-*.md - These are the individual projects. These files look like this: --- title: High-throughput approaches to understand conserved drug responses image: worms_drugs2.jpg order: 1 --- Because of the efforts of a number of highly dedicated scientists and citizen volunteers... To this end, we deep sequenced all of these strains... The page includes a header (the items located between --- ) which includes a number of important items. title - the title to display for the research area. image - An image for that research area/project. This is the base name of the image placed in /assets/img/research/ order - A number indicating the order you would like the page ot appear in. Order is descending and any set of numbers can be used to determine sort order (e.g. 1, 2, 5, 8, 1000).","title":"Research"},{"location":"labsite/#publications","text":"Elements used to construct the publications page of the website are stored in two places: _data/pubs_data.yaml - The publications data stores authors, pub date, journal, etc. publications/ - The publications folder for PDFs, thumbnails, and supplementary files. (1) Download a PDF of the publication You will want to remove any additional PDF pages (e.g. cover sheets) if there are any present in the PDF. See this guide for information on removing pages from a PDF. Save the PDF to /publications/[year][tag] Where tag is a unique identifier for the publication. In general, these have been the first author or the journal or a combination of both. (Optional) PMID Known If the PubMed Identifier (PMID) is known for the publication, you can add it to the file publications/publications_list.txt . (2) Run build.sh The build.sh script does a variety of tasks for the website. For publications - it will generate thumbnails. It will also fetch information for publications and add it to the _data/pubs_data.yaml file if a PMID has been provided. If you did not add a PMID, you will have to manually add authors, journal, etc. to the _data/pubs_data.yaml file. (3) Edit _data/pubs_data.yaml The publication should now be added either manually or automatically to _data/pubs_data.yaml and should look something like this: - Authors: [Laricchia KM, Zdraljevic S, Cook DE, Andersen EC] Citations: 0 DOI: 10.1093/molbev/msx155 Date_Published: 2017 May 09 Journal: Molecular Biology and Evolution PMID: 28486636 Title: Natural variation in the distribution and abundance of transposable elements across the Caenorhabditis elegans species The first thing you will want to do is associate the publication with the PDF you added. Add a PDF line for that: - Authors: [Laricchia KM, Zdraljevic S, Cook DE, Andersen EC] Citations: 0 DOI: 10.1093/molbev/msx155 Date_Published: 2017 May 09 Journal: Molecular Biology and Evolution PMID: 28486636 Title: Natural variation in the distribution and abundance of transposable elements across the <em>Caenorhabditis elegans</em> species PDF: 2017Laricchia You can also italicize text by adding <em> tags around words as shown above ( <em>Caenorhabditis elegans</em> ). Important Before pushing any changes to GitHub, you will want to preview the changes locally using jekyll serve . (4) Add supplementary data Supplemental data and figures are stored in publications/[pdf_name] . For example, 2017Laricchia has an associated folder in publications/ where supplemental data and figures are stored.","title":"Publications"},{"location":"labsite/#photo_albums","text":"Photo albums can be added to the Andersen Labsite. Adding albums requires two utilities to be installed on your computer: (a) Image Magick (b) exiftool These can easily be installed with homebrew . should have been installed during Setup (above), but if not you can install them using the following: brew install imagemagick brew install exiftool (1) Place images in a folder and name it according to the following schema: YYYY-MM-DD-title For example, 2017-08-05-Hawaii Trip . (2) Move that folder to /people/albums/ (3) Run the build.sh script in the root of the andersenlab.github.io repo. The build.sh script will do the following: (a) Construct pages for the album being published. (b) Decrease the size of the images in the album (max width=1200). Note The build.sh script also performs other maintenance-related tasks. It is fine to run this script at anytime. You can run the script using: bash build.sh (4) Add the images using git and push to GitHub You can easily add all images using: git add *.jpg (5) Push changes to github git push","title":"Photo Albums"},{"location":"labsite/#software","text":"If you can write software you should be able to figure out how to update this section. It's markdown/html and not overly complicated.","title":"Software"},{"location":"nextflow/","text":"Setting up Quest \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Nextflow"},{"location":"nextflow/#setting_up_quest","text":"For full documentation visit mkdocs.org .","title":"Setting up Quest"},{"location":"nextflow/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"nextflow/#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"nil/","text":"nil-nf \u00b6 \u00b6 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d","title":"nil-nf"},{"location":"nil/#nil-nf","text":"","title":"nil-nf"},{"location":"pipeline-cegwas/","text":"NIL-NF \u00b6 The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/ Usage \u00b6 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default). Parameters \u00b6 --debug \u00b6 The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference> --cores \u00b6 The number of cores to use during alignments and variant calling. --A, --B \u00b6 Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details. --cA, --cB \u00b6 The color to use for parental strain A and B on plots. --out \u00b6 A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains. --fqs (FASTQs) \u00b6 In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible. --vcf (Parental VCF) \u00b6 Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz --reference \u00b6 A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz --tmpdir \u00b6 A directory for storing temporary data. Output \u00b6 The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt log.txt \u00b6 A summary of the nextflow run. duplicates/ \u00b6 bam_duplicates.tsv - A summary of duplicate reads from aligned bams. fq/ \u00b6 fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq SM/ \u00b6 If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level. hmm/ \u00b6 gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file. plots/ \u00b6 coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent. sitelist/ \u00b6 <A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains. vcf/ \u00b6 gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"Cegwas"},{"location":"pipeline-cegwas/#nil-nf","text":"The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/","title":"NIL-NF"},{"location":"pipeline-cegwas/#usage","text":"\u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default).","title":"Usage"},{"location":"pipeline-cegwas/#parameters","text":"","title":"Parameters"},{"location":"pipeline-cegwas/#--debug","text":"The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference>","title":"--debug"},{"location":"pipeline-cegwas/#--cores","text":"The number of cores to use during alignments and variant calling.","title":"--cores"},{"location":"pipeline-cegwas/#--a_--b","text":"Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details.","title":"--A, --B"},{"location":"pipeline-cegwas/#--ca_--cb","text":"The color to use for parental strain A and B on plots.","title":"--cA, --cB"},{"location":"pipeline-cegwas/#--out","text":"A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains.","title":"--out"},{"location":"pipeline-cegwas/#--fqs_fastqs","text":"In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible.","title":"--fqs (FASTQs)"},{"location":"pipeline-cegwas/#--vcf_parental_vcf","text":"Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz","title":"--vcf (Parental VCF)"},{"location":"pipeline-cegwas/#--reference","text":"A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz","title":"--reference"},{"location":"pipeline-cegwas/#--tmpdir","text":"A directory for storing temporary data.","title":"--tmpdir"},{"location":"pipeline-cegwas/#output","text":"The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt","title":"Output"},{"location":"pipeline-cegwas/#logtxt","text":"A summary of the nextflow run.","title":"log.txt"},{"location":"pipeline-cegwas/#duplicates","text":"bam_duplicates.tsv - A summary of duplicate reads from aligned bams.","title":"duplicates/"},{"location":"pipeline-cegwas/#fq","text":"fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq","title":"fq/"},{"location":"pipeline-cegwas/#sm","text":"If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level.","title":"SM/"},{"location":"pipeline-cegwas/#hmm","text":"gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file.","title":"hmm/"},{"location":"pipeline-cegwas/#plots","text":"coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent.","title":"plots/"},{"location":"pipeline-cegwas/#sitelist","text":"<A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains.","title":"sitelist/"},{"location":"pipeline-cegwas/#vcf","text":"gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"vcf/"},{"location":"pipeline-nil/","text":"NIL-NF \u00b6 The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Docker image andersenlab/nil-ril Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/ Docker image \u00b6 The docker image used by the nil-nf pipeline is the nil-ril docker image: andersenlab/nil-ril \u00b6 The Dockerfile is stored in the root of the nil-nf github repo and is automatically built on Dockerhub whenever the repo is pushed. Usage \u00b6 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default). Parameters \u00b6 --debug \u00b6 The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference> --cores \u00b6 The number of cores to use during alignments and variant calling. --A, --B \u00b6 Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details. --cA, --cB \u00b6 The color to use for parental strain A and B on plots. --out \u00b6 A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains. --fqs (FASTQs) \u00b6 In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible. --vcf (Parental VCF) \u00b6 Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz --reference \u00b6 A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz --tmpdir \u00b6 A directory for storing temporary data. Output \u00b6 The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt log.txt \u00b6 A summary of the nextflow run. duplicates/ \u00b6 bam_duplicates.tsv - A summary of duplicate reads from aligned bams. fq/ \u00b6 fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq SM/ \u00b6 If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level. hmm/ \u00b6 gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file. plots/ \u00b6 coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent. sitelist/ \u00b6 <A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains. vcf/ \u00b6 Important gt_hmm_fill.tsv is for visualization purposes only. To determine breakpoints you should use gt_hmm.tsv . gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"NIL"},{"location":"pipeline-nil/#nil-nf","text":"The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Docker image andersenlab/nil-ril Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/","title":"NIL-NF"},{"location":"pipeline-nil/#docker_image","text":"The docker image used by the nil-nf pipeline is the nil-ril docker image:","title":"Docker image"},{"location":"pipeline-nil/#andersenlabnil-ril","text":"The Dockerfile is stored in the root of the nil-nf github repo and is automatically built on Dockerhub whenever the repo is pushed.","title":"andersenlab/nil-ril"},{"location":"pipeline-nil/#usage","text":"\u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default).","title":"Usage"},{"location":"pipeline-nil/#parameters","text":"","title":"Parameters"},{"location":"pipeline-nil/#--debug","text":"The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference>","title":"--debug"},{"location":"pipeline-nil/#--cores","text":"The number of cores to use during alignments and variant calling.","title":"--cores"},{"location":"pipeline-nil/#--a_--b","text":"Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details.","title":"--A, --B"},{"location":"pipeline-nil/#--ca_--cb","text":"The color to use for parental strain A and B on plots.","title":"--cA, --cB"},{"location":"pipeline-nil/#--out","text":"A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains.","title":"--out"},{"location":"pipeline-nil/#--fqs_fastqs","text":"In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible.","title":"--fqs (FASTQs)"},{"location":"pipeline-nil/#--vcf_parental_vcf","text":"Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz","title":"--vcf (Parental VCF)"},{"location":"pipeline-nil/#--reference","text":"A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz","title":"--reference"},{"location":"pipeline-nil/#--tmpdir","text":"A directory for storing temporary data.","title":"--tmpdir"},{"location":"pipeline-nil/#output","text":"The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt","title":"Output"},{"location":"pipeline-nil/#logtxt","text":"A summary of the nextflow run.","title":"log.txt"},{"location":"pipeline-nil/#duplicates","text":"bam_duplicates.tsv - A summary of duplicate reads from aligned bams.","title":"duplicates/"},{"location":"pipeline-nil/#fq","text":"fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq","title":"fq/"},{"location":"pipeline-nil/#sm","text":"If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level.","title":"SM/"},{"location":"pipeline-nil/#hmm","text":"gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file.","title":"hmm/"},{"location":"pipeline-nil/#plots","text":"coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent.","title":"plots/"},{"location":"pipeline-nil/#sitelist","text":"<A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains.","title":"sitelist/"},{"location":"pipeline-nil/#vcf","text":"Important gt_hmm_fill.tsv is for visualization purposes only. To determine breakpoints you should use gt_hmm.tsv . gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"vcf/"},{"location":"pipeline-ril/","text":"RIL-NF \u00b6 The RIL-nf pipeline will align, call variants, and generate datasets for RIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. RIL-NF Docker image andersenlab/nil-ril Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/ Docker image \u00b6 The docker image used by the ril-nf pipeline is the nil-ril docker image: andersenlab/nil-ril \u00b6 The Dockerfile is stored in the root of the nil-nf github repo and is automatically built on Dockerhub whenever that repo is pushed. Usage \u00b6 \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2584 \u2584\u2584 \u2584 \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2588\u2591\u258c \u2580\u2580\u2580\u2580\u2588\u2591\u2588\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2588\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2588\u2591\u2588\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2584\u2584\u2584\u2584\u2588\u2591\u2588\u2584\u2584\u2584\u2584 \u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u258c \u2590\u2591\u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u2591\u258c\u2590\u2591\u258c \u2580 \u2580 \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2580 \u2580\u2580 \u2580 parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results RIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/RIL-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default). Parameters \u00b6 --debug \u00b6 The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference> --cores \u00b6 The number of cores to use during alignments and variant calling. --A, --B \u00b6 Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details. --cA, --cB \u00b6 The color to use for parental strain A and B on plots. --out \u00b6 A directory in which to output results. By default it will be RIL-A-B-YYYY-MM-DD where A and be are the parental strains. --fqs (FASTQs) \u00b6 In order to process RIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: RIL_01 RIL_01_ID S16 RIL_01_1.fq.gz RIL_01_2.fq.gz RIL_02 RIL_02_ID S1 RIL_02_1.fq.gz RIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path RIL_01 RIL_01_ID S16 RIL_01_1.fq.gz RIL_01_2.fq.gz RIL_02 RIL_02_ID S1 RIL_02_1.fq.gz RIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: RIL_SEQ_DATA/ \u251c\u2500\u2500 RIL_01_1.fq.gz \u251c\u2500\u2500 RIL_01_2.fq.gz \u251c\u2500\u2500 RIL_02_1.fq.gz \u251c\u2500\u2500 RIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on RIL data. RIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible. --vcf (Parental VCF) \u00b6 Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz --reference \u00b6 A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz --tmpdir \u00b6 A directory for storing temporary data. Output \u00b6 The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 RIL.filtered.stats.txt \u251c\u2500\u2500 RIL.filtered.vcf.gz \u251c\u2500\u2500 RIL.filtered.vcf.gz.csi \u251c\u2500\u2500 RIL.hmm.vcf.gz \u251c\u2500\u2500 RIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt log.txt \u00b6 A summary of the nextflow run. duplicates/ \u00b6 bam_duplicates.tsv - A summary of duplicate reads from aligned bams. fq/ \u00b6 fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq SM/ \u00b6 If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level. hmm/ \u00b6 gt_hmm.(png/svg) - Haplotype plot for RILs. gt_hmm.tsv - Long form genotypes file. plots/ \u00b6 coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent. sitelist/ \u00b6 <A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains. vcf/ \u00b6 gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation RIL.filtered.vcf.gz - A VCF genotypes including the RILs and parental genotypes. RIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats RIL.filtered.vcf.gz RIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"RIL"},{"location":"pipeline-ril/#ril-nf","text":"The RIL-nf pipeline will align, call variants, and generate datasets for RIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. RIL-NF Docker image andersenlab/nil-ril Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/","title":"RIL-NF"},{"location":"pipeline-ril/#docker_image","text":"The docker image used by the ril-nf pipeline is the nil-ril docker image:","title":"Docker image"},{"location":"pipeline-ril/#andersenlabnil-ril","text":"The Dockerfile is stored in the root of the nil-nf github repo and is automatically built on Dockerhub whenever that repo is pushed.","title":"andersenlab/nil-ril"},{"location":"pipeline-ril/#usage","text":"\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2584 \u2584\u2584 \u2584 \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2588\u2591\u258c \u2580\u2580\u2580\u2580\u2588\u2591\u2588\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2588\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2588\u2591\u2588\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2588\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c \u2584\u2584\u2584\u2584\u2588\u2591\u2588\u2584\u2584\u2584\u2584 \u2590\u2591\u2588\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584 \u2590\u2591\u258c \u2590\u2591\u2590\u2591\u258c\u2590\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c\u2590\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u258c \u2590\u2591\u258c \u2590\u2591\u2591\u258c\u2590\u2591\u258c \u2580 \u2580 \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580 \u2580 \u2580\u2580 \u2580 parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results RIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/RIL-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default).","title":"Usage"},{"location":"pipeline-ril/#parameters","text":"","title":"Parameters"},{"location":"pipeline-ril/#--debug","text":"The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference>","title":"--debug"},{"location":"pipeline-ril/#--cores","text":"The number of cores to use during alignments and variant calling.","title":"--cores"},{"location":"pipeline-ril/#--a_--b","text":"Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details.","title":"--A, --B"},{"location":"pipeline-ril/#--ca_--cb","text":"The color to use for parental strain A and B on plots.","title":"--cA, --cB"},{"location":"pipeline-ril/#--out","text":"A directory in which to output results. By default it will be RIL-A-B-YYYY-MM-DD where A and be are the parental strains.","title":"--out"},{"location":"pipeline-ril/#--fqs_fastqs","text":"In order to process RIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: RIL_01 RIL_01_ID S16 RIL_01_1.fq.gz RIL_01_2.fq.gz RIL_02 RIL_02_ID S1 RIL_02_1.fq.gz RIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path RIL_01 RIL_01_ID S16 RIL_01_1.fq.gz RIL_01_2.fq.gz RIL_02 RIL_02_ID S1 RIL_02_1.fq.gz RIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: RIL_SEQ_DATA/ \u251c\u2500\u2500 RIL_01_1.fq.gz \u251c\u2500\u2500 RIL_01_2.fq.gz \u251c\u2500\u2500 RIL_02_1.fq.gz \u251c\u2500\u2500 RIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on RIL data. RIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible.","title":"--fqs (FASTQs)"},{"location":"pipeline-ril/#--vcf_parental_vcf","text":"Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz","title":"--vcf (Parental VCF)"},{"location":"pipeline-ril/#--reference","text":"A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz","title":"--reference"},{"location":"pipeline-ril/#--tmpdir","text":"A directory for storing temporary data.","title":"--tmpdir"},{"location":"pipeline-ril/#output","text":"The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 RIL.filtered.stats.txt \u251c\u2500\u2500 RIL.filtered.vcf.gz \u251c\u2500\u2500 RIL.filtered.vcf.gz.csi \u251c\u2500\u2500 RIL.hmm.vcf.gz \u251c\u2500\u2500 RIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt","title":"Output"},{"location":"pipeline-ril/#logtxt","text":"A summary of the nextflow run.","title":"log.txt"},{"location":"pipeline-ril/#duplicates","text":"bam_duplicates.tsv - A summary of duplicate reads from aligned bams.","title":"duplicates/"},{"location":"pipeline-ril/#fq","text":"fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq","title":"fq/"},{"location":"pipeline-ril/#sm","text":"If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level.","title":"SM/"},{"location":"pipeline-ril/#hmm","text":"gt_hmm.(png/svg) - Haplotype plot for RILs. gt_hmm.tsv - Long form genotypes file.","title":"hmm/"},{"location":"pipeline-ril/#plots","text":"coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent.","title":"plots/"},{"location":"pipeline-ril/#sitelist","text":"<A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains.","title":"sitelist/"},{"location":"pipeline-ril/#vcf","text":"gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation RIL.filtered.vcf.gz - A VCF genotypes including the RILs and parental genotypes. RIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats RIL.filtered.vcf.gz RIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"vcf/"},{"location":"pipeline-trimming/","text":"NIL-NF \u00b6 The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/ Usage \u00b6 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default). Parameters \u00b6 --debug \u00b6 The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference> --cores \u00b6 The number of cores to use during alignments and variant calling. --A, --B \u00b6 Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details. --cA, --cB \u00b6 The color to use for parental strain A and B on plots. --out \u00b6 A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains. --fqs (FASTQs) \u00b6 In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible. --vcf (Parental VCF) \u00b6 Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz --reference \u00b6 A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz --tmpdir \u00b6 A directory for storing temporary data. Output \u00b6 The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt log.txt \u00b6 A summary of the nextflow run. duplicates/ \u00b6 bam_duplicates.tsv - A summary of duplicate reads from aligned bams. fq/ \u00b6 fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq SM/ \u00b6 If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level. hmm/ \u00b6 gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file. plots/ \u00b6 coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent. sitelist/ \u00b6 <A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains. vcf/ \u00b6 gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"Trimming"},{"location":"pipeline-trimming/#nil-nf","text":"The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/","title":"NIL-NF"},{"location":"pipeline-trimming/#usage","text":"\u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default).","title":"Usage"},{"location":"pipeline-trimming/#parameters","text":"","title":"Parameters"},{"location":"pipeline-trimming/#--debug","text":"The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference>","title":"--debug"},{"location":"pipeline-trimming/#--cores","text":"The number of cores to use during alignments and variant calling.","title":"--cores"},{"location":"pipeline-trimming/#--a_--b","text":"Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details.","title":"--A, --B"},{"location":"pipeline-trimming/#--ca_--cb","text":"The color to use for parental strain A and B on plots.","title":"--cA, --cB"},{"location":"pipeline-trimming/#--out","text":"A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains.","title":"--out"},{"location":"pipeline-trimming/#--fqs_fastqs","text":"In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible.","title":"--fqs (FASTQs)"},{"location":"pipeline-trimming/#--vcf_parental_vcf","text":"Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz","title":"--vcf (Parental VCF)"},{"location":"pipeline-trimming/#--reference","text":"A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz","title":"--reference"},{"location":"pipeline-trimming/#--tmpdir","text":"A directory for storing temporary data.","title":"--tmpdir"},{"location":"pipeline-trimming/#output","text":"The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt","title":"Output"},{"location":"pipeline-trimming/#logtxt","text":"A summary of the nextflow run.","title":"log.txt"},{"location":"pipeline-trimming/#duplicates","text":"bam_duplicates.tsv - A summary of duplicate reads from aligned bams.","title":"duplicates/"},{"location":"pipeline-trimming/#fq","text":"fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq","title":"fq/"},{"location":"pipeline-trimming/#sm","text":"If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level.","title":"SM/"},{"location":"pipeline-trimming/#hmm","text":"gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file.","title":"hmm/"},{"location":"pipeline-trimming/#plots","text":"coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent.","title":"plots/"},{"location":"pipeline-trimming/#sitelist","text":"<A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains.","title":"sitelist/"},{"location":"pipeline-trimming/#vcf","text":"gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"vcf/"},{"location":"pipeline-wi/","text":"NIL-NF \u00b6 The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/ Usage \u00b6 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default). Parameters \u00b6 --debug \u00b6 The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference> --cores \u00b6 The number of cores to use during alignments and variant calling. --A, --B \u00b6 Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details. --cA, --cB \u00b6 The color to use for parental strain A and B on plots. --out \u00b6 A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains. --fqs (FASTQs) \u00b6 In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible. --vcf (Parental VCF) \u00b6 Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz --reference \u00b6 A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz --tmpdir \u00b6 A directory for storing temporary data. Output \u00b6 The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt log.txt \u00b6 A summary of the nextflow run. duplicates/ \u00b6 bam_duplicates.tsv - A summary of duplicate reads from aligned bams. fq/ \u00b6 fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq SM/ \u00b6 If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level. hmm/ \u00b6 gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file. plots/ \u00b6 coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent. sitelist/ \u00b6 <A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains. vcf/ \u00b6 gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"WI"},{"location":"pipeline-wi/#nil-nf","text":"The nil-nf pipeline will align, call variants, and generate datasets for NIL sequence data. It runs a hidden-markov-model to fill in missing genotypes from low-coverage sequence data. NIL-NF Usage Parameters --debug --cores --A, --B --cA, --cB --out --fqs (FASTQs) --vcf (Parental VCF) --reference --tmpdir Output log.txt duplicates/ fq/ SM/ hmm/ plots/ sitelist/ vcf/","title":"NIL-NF"},{"location":"pipeline-wi/#usage","text":"\u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d parameters description Set/Default ========== =========== ======= --debug Set to 'true' to test false --cores Number of cores 4 --A Parent A N2 --B Parent B CB4856 --cA Parent A color (for plots) #0080FF --cB Parent B color (for plots) #FF8000 --out Directory to output results NIL-N2-CB4856-2017-09-27 --fqs fastq file (see help) (required) --reference Reference Genome /Users/dancook/Documents/git/nil-nf/reference/WS245.fa.gz --vcf VCF to fetch parents from (required) --tmpdir A temporary directory tmp/ The Set/Default column shows what the value is currently set to or would be set to if it is not specified (it's default).","title":"Usage"},{"location":"pipeline-wi/#parameters","text":"","title":"Parameters"},{"location":"pipeline-wi/#--debug","text":"The pipeline comes pre-packed with fastq's and a VCF that can be used to debug. You can use the following command to debug: nextflow run main.nf --debug --reference=<path to reference>","title":"--debug"},{"location":"pipeline-wi/#--cores","text":"The number of cores to use during alignments and variant calling.","title":"--cores"},{"location":"pipeline-wi/#--a_--b","text":"Two parental strains must be provided. By default these are N2 and CB4856. The parental strains provided must be present in the VCF provided. Their genotypes are pulled from that VCF and used to generate the HMM. See below for more details.","title":"--A, --B"},{"location":"pipeline-wi/#--ca_--cb","text":"The color to use for parental strain A and B on plots.","title":"--cA, --cB"},{"location":"pipeline-wi/#--out","text":"A directory in which to output results. By default it will be NIL-A-B-YYYY-MM-DD where A and be are the parental strains.","title":"--out"},{"location":"pipeline-wi/#--fqs_fastqs","text":"In order to process NIL data, you need to move the sequence data to a folder and create a fq_sheet.tsv . This file defines the fastqs that should be processed. The fastq files are relative to that file. The fastq sheet details the FASTQ files and their associated strains. It should be tab-delimited and look like this: NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz Notice that the file does not include a header. The table with corresponding columns looks like this. strain fastq_pair_id library fastq-1-path fastq-2-path NIL_01 NIL_01_ID S16 NIL_01_1.fq.gz NIL_01_2.fq.gz NIL_02 NIL_02_ID S1 NIL_02_1.fq.gz NIL_02_2.fq.gz The columns are detailed below: strain - The name of the strain. If a strain was sequenced multiple times this file is used to identify that fact and merge those fastq-pairs together following alignment. fastq_pair_id - This must be unique identifier for all individual FASTQ pairs. library - A string identifying the DNA library. If you sequenced a strain from different library preps it can be beneficial when calling variants. The string can be arbitrary (e.g. LIB1) as well if only one library prep was used. fastq-1-path - The relative path of the first fastq. fastq-2-path - The relative path of the second fastq. This file needs to be placed along with the sequence data into a folder. The tree will look like this: NIL_SEQ_DATA/ \u251c\u2500\u2500 NIL_01_1.fq.gz \u251c\u2500\u2500 NIL_01_2.fq.gz \u251c\u2500\u2500 NIL_02_1.fq.gz \u251c\u2500\u2500 NIL_02_2.fq.gz \u2514\u2500\u2500 fq_sheet.tsv Set --fqs as --fqs=/the/path/to/fq_sheet.tsv . Important Do not perform any pre-processing on NIL data. NIL-data is low-coverage by design and you want to retain as much sequence data (however poor) as possible.","title":"--fqs (FASTQs)"},{"location":"pipeline-wi/#--vcf_parental_vcf","text":"Before you begin, you will need access to a VCF with high-coverage data from the parental strains. In general, this can be obtained using the latest release of the wild-isolate data which is usually located in the b1059 analysis folder. For example, you would likely want to use: /projects/b1059/analysis/WI-20170531/vcf/WI.20170531.hard-filter.vcf.gz This is the hard-filtered VCF, meaning that poor quality variants have been stripped. Use hard-filtered VCFs for this pipeline. Set the parental VCF as --vcf=/the/path/to/WI.20170531.hard-filter.vcf.gz","title":"--vcf (Parental VCF)"},{"location":"pipeline-wi/#--reference","text":"A fasta reference indexed with BWA. On Quest, the reference is available here: /projects/b1059/data/genomes/c_elegans/WS245/WS245.fa.gz","title":"--reference"},{"location":"pipeline-wi/#--tmpdir","text":"A directory for storing temporary data.","title":"--tmpdir"},{"location":"pipeline-wi/#output","text":"The final output directory looks like this: . \u251c\u2500\u2500 log.txt \u251c\u2500\u2500 fq \u2502 \u251c\u2500\u2500 fq_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 fq_bam_stats.tsv \u2502 \u251c\u2500\u2500 fq_coverage.full.tsv \u2502 \u2514\u2500\u2500 fq_coverage.tsv \u251c\u2500\u2500 SM \u2502 \u251c\u2500\u2500 SM_bam_idxstats.tsv \u2502 \u251c\u2500\u2500 SM_bam_stats.tsv \u2502 \u251c\u2500\u2500 SM_coverage.full.tsv \u2502 \u2514\u2500\u2500 SM_coverage.tsv \u251c\u2500\u2500 hmm \u2502 \u251c\u2500\u2500 gt_hmm.(png/svg) \u2502 \u2514\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 bam \u2502 \u2514\u2500\u2500 <BAMS + indices> \u251c\u2500\u2500 duplicates \u2502 \u2514\u2500\u2500 bam_duplicates.tsv \u251c\u2500\u2500 sitelist \u2502 \u251c\u2500\u2500 N2.CB4856.sitelist.tsv.gz \u2502 \u2514\u2500\u2500 N2.CB4856.sitelist.tsv.gz.tbi \u2514\u2500\u2500 vcf \u251c\u2500\u2500 NIL.filtered.stats.txt \u251c\u2500\u2500 NIL.filtered.vcf.gz \u251c\u2500\u2500 NIL.filtered.vcf.gz.csi \u251c\u2500\u2500 NIL.hmm.vcf.gz \u251c\u2500\u2500 NIL.hmm.vcf.gz.csi \u251c\u2500\u2500 gt_hmm.tsv \u251c\u2500\u2500 gt_hmm_fill.tsv \u2514\u2500\u2500 union_vcfs.txt","title":"Output"},{"location":"pipeline-wi/#logtxt","text":"A summary of the nextflow run.","title":"log.txt"},{"location":"pipeline-wi/#duplicates","text":"bam_duplicates.tsv - A summary of duplicate reads from aligned bams.","title":"duplicates/"},{"location":"pipeline-wi/#fq","text":"fq_bam_idxstats.tsv - A summary of mapped and unmapped reads by fastq pair. fq_bam_stats.tsv - BAM summary by fastq pair. fq_coverage.full.tsv - Coverage summary by chromosome fq_coverage.tsv - Simple coverage file by fastq","title":"fq/"},{"location":"pipeline-wi/#sm","text":"If you have multiple fastq pairs per sample, their alignments will be combined into a strain or sample-level BAM and the results will be output to this directory. SM_bam_idxstats.tsv - A summary of mapped and unmapped reads by sample. SM_bam_stats.tsv - BAM summary at the sample level SM_coverage.full.tsv - Coverage at the sample level SM_coverage.tsv - Simple coverage at the sample level.","title":"SM/"},{"location":"pipeline-wi/#hmm","text":"gt_hmm.(png/svg) - Haplotype plot for NILs. gt_hmm.tsv - Long form genotypes file.","title":"hmm/"},{"location":"pipeline-wi/#plots","text":"coverage_comparison.(png/svg/pdf) - Compares FASTQ and Sample-level coverage. Note that coverage is not simply cumulative. Only uniquely mapped reads count towards coverage, so it is possible that the sample-level coverage will not equal to the cumulative sum of the coverages of individual FASTQ pairs. duplicates.(png/svg/pdf) - Coverage vs. percent duplicated. unmapped_reads.(png/svg/pdf) - Coverage vs. unmapped read percent.","title":"plots/"},{"location":"pipeline-wi/#sitelist","text":"<A>.<B>.sitelist.tsv.gz[+.tbi] - A tabix-indexed list of sites found to be different between both parental strains.","title":"sitelist/"},{"location":"pipeline-wi/#vcf","text":"gt_hmm.tsv - Haplotypes defined by region with associated information. gt_hmm_fill.tsv - Same as above, but using --infill and --endfill with VCF-Kit. For more information, see VCF-Kit Documentation NIL.filtered.vcf.gz - A VCF genotypes including the NILs and parental genotypes. NIL.filtered.stats.txt - Summary of filtered genotypes. Generated by bcftools stats NIL.filtered.vcf.gz NIL.hmm.vcf.gz - The RIL VCF as output by VCF-Kit; HMM applied to determine genotypes. union_vcfs.txt - A list of VCFs that were merged to generate RIL.filter.vcf.gz","title":"vcf/"},{"location":"quest-intro/","text":"Introduction \u00b6 Introduction Signing into Quest Home Directory Projects Installing and using software Using module Using linuxbrew Starting interactive jobs Using Screen The Andersen Lab makes use of Quest, the supercomputer at Northwestern. Take some time to read over the overview of what Quest is, what it does, how to use it, and how to sign up: Quest Documentation Signing into Quest \u00b6 After you gain access to the cluster you can login using: ssh <netid>@quest.it.northwestern.edu I recommend setting an alias in your .bash_profile to make logging in quicker: alias quest=\"ssh <netid>@quest.it.northwestern.edu\" The above line makes it so you simply type quest and the login process is initiated. If you are not familiar with what a bash profile is, take a look at this . When you login it is important to be conscientious of the fact that you are on a login node. You should not be running any sort of heavy duty operation on these nodes. Instead, any analysis you perform should be submitted as a job. Home Directory \u00b6 Logging in places you in your home directory. You can install software in your home directory for use when you run jobs, or for small files/analysis. Your home directory has a quota of 80 Gb. More information on quotas, storage, etc. . More information is provided below to help install and use software. Projects \u00b6 Quest is broadly organized into projects. Projects have associated with them storage, nodes, and users. The Andersen lab has access to two projects. b1042 - The 'Genomics' Project has 155 Tb of space and 100 nodes associated with it. This space is shared with other labs and is designed for temporary use only (covered in greater detail in the Nextflow Section). The space is available at /projects/b1042/AndersenLab/ . By default, files are deleted after 30 days. b1059 - The Andersen Lab Project. b1059 does not have any nodes associated with it, but it does have 10 Tb of storage. b1059 storage is located at: /projects/b1059/ . Installing and using software \u00b6 Using module \u00b6 Quest comes with a command called module that allows you to load software for use. The following commands can be used to see/load software. module avail - List available software. module load software/version - Load a software package (e.g. module load R/3.3.1 ). Using linuxbrew \u00b6 Linuxbrew is a fork of Homebrew - which is a package manager for MacOSX. Linuxbrew should be installed in your home directory using the following command: A lot of the software you use can be installed using a bottle format. The Andersen Lab has access to the 'Genomics' project Starting interactive jobs \u00b6 msub -I -A b1042 Using Screen \u00b6 Ctrl + A","title":"Introduction"},{"location":"quest-intro/#introduction","text":"Introduction Signing into Quest Home Directory Projects Installing and using software Using module Using linuxbrew Starting interactive jobs Using Screen The Andersen Lab makes use of Quest, the supercomputer at Northwestern. Take some time to read over the overview of what Quest is, what it does, how to use it, and how to sign up: Quest Documentation","title":"Introduction"},{"location":"quest-intro/#signing_into_quest","text":"After you gain access to the cluster you can login using: ssh <netid>@quest.it.northwestern.edu I recommend setting an alias in your .bash_profile to make logging in quicker: alias quest=\"ssh <netid>@quest.it.northwestern.edu\" The above line makes it so you simply type quest and the login process is initiated. If you are not familiar with what a bash profile is, take a look at this . When you login it is important to be conscientious of the fact that you are on a login node. You should not be running any sort of heavy duty operation on these nodes. Instead, any analysis you perform should be submitted as a job.","title":"Signing into Quest"},{"location":"quest-intro/#home_directory","text":"Logging in places you in your home directory. You can install software in your home directory for use when you run jobs, or for small files/analysis. Your home directory has a quota of 80 Gb. More information on quotas, storage, etc. . More information is provided below to help install and use software.","title":"Home Directory"},{"location":"quest-intro/#projects","text":"Quest is broadly organized into projects. Projects have associated with them storage, nodes, and users. The Andersen lab has access to two projects. b1042 - The 'Genomics' Project has 155 Tb of space and 100 nodes associated with it. This space is shared with other labs and is designed for temporary use only (covered in greater detail in the Nextflow Section). The space is available at /projects/b1042/AndersenLab/ . By default, files are deleted after 30 days. b1059 - The Andersen Lab Project. b1059 does not have any nodes associated with it, but it does have 10 Tb of storage. b1059 storage is located at: /projects/b1059/ .","title":"Projects"},{"location":"quest-intro/#installing_and_using_software","text":"","title":"Installing and using software"},{"location":"quest-intro/#using_module","text":"Quest comes with a command called module that allows you to load software for use. The following commands can be used to see/load software. module avail - List available software. module load software/version - Load a software package (e.g. module load R/3.3.1 ).","title":"Using module"},{"location":"quest-intro/#using_linuxbrew","text":"Linuxbrew is a fork of Homebrew - which is a package manager for MacOSX. Linuxbrew should be installed in your home directory using the following command: A lot of the software you use can be installed using a bottle format. The Andersen Lab has access to the 'Genomics' project","title":"Using linuxbrew"},{"location":"quest-intro/#starting_interactive_jobs","text":"msub -I -A b1042","title":"Starting interactive jobs"},{"location":"quest-intro/#using_screen","text":"Ctrl + A","title":"Using Screen"},{"location":"quest-linuxbrew/","text":"Linuxbrew \u00b6","title":"Linuxbrew"},{"location":"quest-linuxbrew/#linuxbrew","text":"","title":"Linuxbrew"},{"location":"quest-mount/","text":"1. Download and Install Fuse for Mac OS https://osxfuse.github.io/ 2. Install sshfs You can use the link on https://osxfuse.github.io/ or use: brew install sshfs 3. Create a folder in your documents called b1059 mkdir ~/b1059 4. Mount our labs quest project folder ( b1059 ) to the b1059 folder you created locally sshfs <NETID>@quest.it.northwestern.edu:/projects/b1059/ ~/Documents/b1059 -ovolname=b1059 To mount alignments of isotypes at this location: sshfs <NETID>@quest.it.northwestern.edu:/projects/b1059/data/alignments/WI/isotype ~/Documents/b1059 -ovolname=b1059","title":"Mounting Quest"},{"location":"quest-nextflow/","text":"Installation Quest cluster configuration Global Configuration: ~/.nextflow/config Pipeline Configuration Resources Installation \u00b6 Nextflow can be installed with linuxbrew . Use: brew tap homebrew/science brew install nextflow Quest cluster configuration \u00b6 Configuration files allow you to define the way a pipeline is executed on Quest. Read the quest documentation on configuration files Configuration files are defined at a global level in ~/.nextflow/config and on a per-pipeline basis within <pipeline_directory>/nextflow.config . Settings written in <pipeline_directory>/nextflow.config override settings written in ~/.nextflow/config . Global Configuration: ~/.nextflow/config \u00b6 In order to use nextflow on quest you will need to define some global variables regarding the process. Our lab utilizies nodes and space dedicated to genomics projects. In order to access these resources your account will need to be granted access. Contact Quest and request access to the genomics nodes and project b1042 . Once you have access you will need to modify your global configuration. Set your ~/.nextflow/config file to be the following: process { module='R/3.3.1' executor = 'pbs' queue = 'genomicsguest' clusterOptions = '-A b1042 -l walltime=24:00:00 -e errlog.txt' } workDir = \"/projects/b1042/AndersenLab/work\" tmpDir = \"/projects/b1042/AndersenLab/tmp\" This configuration file does the following: module='R/3.3.1' - automatically loads R for all processes. Sets the executor to pbs (which is what Quest uses) Sets the queue to genomicsguest which submits jobs to genomics nodes. clusterOptions - Sets the account to b1042 ; granting access to genomics-dedicated scratch space. workDir - Sets the working directory to scratch space on b1042. tmpDir - Creates a temporary working directory. This can be used within workflows when necessary. Pipeline Configuration \u00b6 At the pipeline level you will want to define things like the number of processors for a given process, the analysis output directory, or the reference genome used. The following is an example from the wi-nf pipeline: genome = \"WS245\" reference = \"/projects/b1059/data/genomes/c_elegans/${genome}/${genome}.fa.gz\" alignment_cores = 16 variant_cores = 6 compression_threads = 4 //date = new Date().format( 'yyyyMMdd' ) date = 20170531 analysis_dir = \"/projects/b1059/analysis/WI-${date}\" SM_alignments_dir = \"/projects/b1059/data/alignments\" beagle_location = \"/projects/b1059/software/beagle/beagle.jar\" process { module='gcc/5.1.0:R/3.3.1' $perform_alignment { cpus = 4 } $call_variants_individual { cpus = 6 memory = '8G' } $call_variants_union { cpus = 6 memory = '8G' } $merge_union_vcf { cpus = 20 memory = '50G' } $filter_union_vcf { cpus = 20 memory = '50G' } $annotate_vcf_snpeff { module='gcc/4.6.3' } $generate_isotype_vcf { errorStrategy='retry' maxRetries=20 maxForks=10 } } Resources \u00b6 Nextflow documentation - Awesome Nextflow pipeline examples - Repository of great nextflow pipelines.","title":"Setting up Nextflow"},{"location":"quest-nextflow/#installation","text":"Nextflow can be installed with linuxbrew . Use: brew tap homebrew/science brew install nextflow","title":"Installation"},{"location":"quest-nextflow/#quest_cluster_configuration","text":"Configuration files allow you to define the way a pipeline is executed on Quest. Read the quest documentation on configuration files Configuration files are defined at a global level in ~/.nextflow/config and on a per-pipeline basis within <pipeline_directory>/nextflow.config . Settings written in <pipeline_directory>/nextflow.config override settings written in ~/.nextflow/config .","title":"Quest cluster configuration"},{"location":"quest-nextflow/#global_configuration_nextflowconfig","text":"In order to use nextflow on quest you will need to define some global variables regarding the process. Our lab utilizies nodes and space dedicated to genomics projects. In order to access these resources your account will need to be granted access. Contact Quest and request access to the genomics nodes and project b1042 . Once you have access you will need to modify your global configuration. Set your ~/.nextflow/config file to be the following: process { module='R/3.3.1' executor = 'pbs' queue = 'genomicsguest' clusterOptions = '-A b1042 -l walltime=24:00:00 -e errlog.txt' } workDir = \"/projects/b1042/AndersenLab/work\" tmpDir = \"/projects/b1042/AndersenLab/tmp\" This configuration file does the following: module='R/3.3.1' - automatically loads R for all processes. Sets the executor to pbs (which is what Quest uses) Sets the queue to genomicsguest which submits jobs to genomics nodes. clusterOptions - Sets the account to b1042 ; granting access to genomics-dedicated scratch space. workDir - Sets the working directory to scratch space on b1042. tmpDir - Creates a temporary working directory. This can be used within workflows when necessary.","title":"Global Configuration: ~/.nextflow/config"},{"location":"quest-nextflow/#pipeline_configuration","text":"At the pipeline level you will want to define things like the number of processors for a given process, the analysis output directory, or the reference genome used. The following is an example from the wi-nf pipeline: genome = \"WS245\" reference = \"/projects/b1059/data/genomes/c_elegans/${genome}/${genome}.fa.gz\" alignment_cores = 16 variant_cores = 6 compression_threads = 4 //date = new Date().format( 'yyyyMMdd' ) date = 20170531 analysis_dir = \"/projects/b1059/analysis/WI-${date}\" SM_alignments_dir = \"/projects/b1059/data/alignments\" beagle_location = \"/projects/b1059/software/beagle/beagle.jar\" process { module='gcc/5.1.0:R/3.3.1' $perform_alignment { cpus = 4 } $call_variants_individual { cpus = 6 memory = '8G' } $call_variants_union { cpus = 6 memory = '8G' } $merge_union_vcf { cpus = 20 memory = '50G' } $filter_union_vcf { cpus = 20 memory = '50G' } $annotate_vcf_snpeff { module='gcc/4.6.3' } $generate_isotype_vcf { errorStrategy='retry' maxRetries=20 maxForks=10 } }","title":"Pipeline Configuration"},{"location":"quest-nextflow/#resources","text":"Nextflow documentation - Awesome Nextflow pipeline examples - Repository of great nextflow pipelines.","title":"Resources"},{"location":"r/","text":"R \u00b6 R Packages \u00b6 The Andersen lab maintains several R packages. cegwas \u00b6 linkagemapping \u00b6 easysorter \u00b6","title":"R"},{"location":"r/#r","text":"","title":"R"},{"location":"r/#r_packages","text":"The Andersen lab maintains several R packages.","title":"R Packages"},{"location":"r/#cegwas","text":"","title":"cegwas"},{"location":"r/#linkagemapping","text":"","title":"linkagemapping"},{"location":"r/#easysorter","text":"","title":"easysorter"},{"location":"travis-ci/","text":"Setting up Quest \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Travis-CI"},{"location":"travis-ci/#setting_up_quest","text":"For full documentation visit mkdocs.org .","title":"Setting up Quest"},{"location":"travis-ci/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"travis-ci/#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"}]}